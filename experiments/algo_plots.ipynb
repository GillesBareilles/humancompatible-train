{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRoundedThresholdv1(a, round_step):\n",
    "    return np.round(a / round_step) * round_step\n",
    "\n",
    "def produce_plots(data,lb, x_axis='iteration', q1=0.25,q2=0.75, f_ylim=(0, 0.75), c_ylim = (-0.01, 0.01)):# save=False, dataset_name=None):\n",
    "    q1 = q1\n",
    "    q2 = q2\n",
    "    q3 = 0.5\n",
    "    \n",
    "\n",
    "    means = data.groupby(x_axis).mean()\n",
    "    q_lower = data.groupby(by=x_axis).quantile(q=q1,interpolation='lower')\n",
    "    q_mid = data.groupby(by=x_axis).quantile(q=q3,interpolation='linear')\n",
    "    q_higher = data.groupby(by=x_axis).quantile(q=q2,interpolation='higher')\n",
    "    \n",
    "    f = plt.figure()\n",
    "    \n",
    "    ax1 = f.add_subplot()\n",
    "\n",
    "    ax1.fill_between(x=means.index, y1=q_lower['Loss'], y2=q_higher['Loss'],alpha=0.4)\n",
    "    ax1.plot(q_lower['Loss'], label=f'Q{int(q1*100)}',c='black', lw=0.6)\n",
    "    ax1.plot(q_higher['Loss'], label=f'Q{int(q2*100)}',c='black', lw=0.6)\n",
    "    ax1.plot(q_mid['Loss'], label=f'Median',c='darkorange', lw=0.6)\n",
    "    ax1.plot(means['Loss'], label='Mean')\n",
    "    xt = ax1.get_xticks()\n",
    "    xt_ind = xt[1:-1] - 1\n",
    "    xt_ind[0] = 0\n",
    "    # ax1.set_xticks(means['SampleSize'].cumsum()[xt_ind])\n",
    "    # ax1.set_xticklabels(labels=np.round(means['SampleSize'].cumsum()[xt_ind], 0), rotation=45)\n",
    "\n",
    "    ax1.set_xlabel('Iteration')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # if save:\n",
    "        # f.savefig('C:/Users/andre/docs/plots/sslalm/income_race/loss\n",
    "    \n",
    "    f_ = plt.figure()\n",
    "    ax2 = f_.add_subplot()\n",
    "\n",
    "    ax2.fill_between(x=means.index, y1=q_lower['C1'], y2=q_higher['C1'],alpha=0.4)\n",
    "    ax2.plot(q_lower['C1'], ls = '-', label=f'Q{int(q1*100)}',c='black', lw=0.6)\n",
    "    ax2.plot(q_higher['C1'], ls = '-', label=f'Q{int(q2*100)}',c='black', lw=0.6)\n",
    "    ax2.plot(q_mid['C1'], label=f'Median',c='darkorange')\n",
    "    ax2.plot(means['C1'], label='Mean')\n",
    "\n",
    "    ax2.set_xlabel('Iteration')\n",
    "    # ax2.set_ylim(bottom=-0.02, top=0.02)\n",
    "    ax2.hlines(y=[-lb, lb], xmin=0, xmax=max(data['iteration']), ls='--',colors='blue', alpha=0.5, label='Constraint bound')\n",
    "    ax2.hlines(y=0, xmin=0, xmax=max(data['iteration']), ls='--', colors='black', alpha=0.5)\n",
    "    ax2.set_ylabel('$L_w-L_b$')\n",
    "    ax2.legend()\n",
    "    return f, f_\n",
    "    \n",
    "def plot_separate_trajectories(data, lb, x_axis, alpha=0.5, lw=1, legend=True):\n",
    "    f = plt.figure()\n",
    "    ax1 = f.add_subplot()\n",
    "    f = plt.figure()\n",
    "    ax2 = f.add_subplot()\n",
    "    for EXP_NUM in data['trial'].unique():\n",
    "        traj = data[data['trial'] == EXP_NUM]\n",
    "        if x_axis == 'time':\n",
    "            x = traj['time']\n",
    "        elif x_axis == 'iteration':\n",
    "            x = traj['iteration']\n",
    "        if isinstance(alpha, list):\n",
    "            _a = alpha[EXP_NUM]\n",
    "        else:\n",
    "            _a = alpha\n",
    "        if _a == 0:\n",
    "            continue\n",
    "        ax1.plot(x, traj['Loss'], label='Loss - trial {EXP_NUM}', alpha=_a, lw=lw)\n",
    "        ax2.plot(x, traj['C1'], label=f'C1 - trial {EXP_NUM}', alpha=_a, lw=lw)\n",
    "    \n",
    "    ax1.set_xlabel('iteration' if x_axis == 'iteration' else 'time, s')\n",
    "    # ax1.set_ybound(0, 1)\n",
    "    ax2.set_xlabel('iteration' if x_axis == 'iteration' else 'time, s')\n",
    "    ax2.hlines(y=[-lb, lb], xmin=0, xmax=max(data[x_axis]), ls='--',colors='blue', alpha=0.5, label='Constraint bound')\n",
    "    ax2.hlines(y=0, xmin=0, xmax=max(data[x_axis]), ls='--', colors='black', alpha=0.5)\n",
    "    # ax2.set_ybound(-0.02, 0.04)\n",
    "    ax2.set_ylabel('$L_w-L_b$')\n",
    "    if legend:\n",
    "        ax2.legend()\n",
    "    # f.show()\n",
    "    \n",
    "def produce_plots_time(data, lb, round_step=0.5, fill='bfill', fill_limit=None, q1=0.25,q2=0.75, f_ylim=(0.4, 0.75), c_ylim = (-0.06, 0.07)):\n",
    "    q3 = 0.5\n",
    "    \n",
    "    data['time_r'] = getRoundedThresholdv1(data['time'], round_step)\n",
    "    \n",
    "    time_step_idx = pd.Index(np.arange(0, max(data['time_r']), step=round_step))\n",
    "    \n",
    "    trials = []\n",
    "    \n",
    "    for EXP_NUM in data['trial'].unique():\n",
    "        trial_stats = data[data['trial'] == EXP_NUM]\n",
    "        trial_stats.index = trial_stats['time_r']\n",
    "        trial_stats= trial_stats.reindex(time_step_idx, copy=True)\n",
    "        trial_stats['time_r'] = trial_stats.index\n",
    "        if fill == 'bfill':\n",
    "            trial_stats.bfill(inplace=True, limit=fill_limit)\n",
    "        elif fill == 'ffill':\n",
    "            trial_stats.ffill(inplace=True, limit=fill_limit)\n",
    "        else:\n",
    "            trial_stats.interpolate(fill, inplace=True, limit_direction='forward')\n",
    "        trials.append(trial_stats)\n",
    "        \n",
    "    trials = pd.concat(trials, ignore_index=True)\n",
    "    trials_gr = trials.groupby('time_r')\n",
    "    \n",
    "    # f, axs = plt.subplots(1,5)\n",
    "    # for EXP_NUM in data['trial'].unique():\n",
    "    #     axs[EXP_NUM].set_title(EXP_NUM)\n",
    "    #     tr = trials[trials['trial'] == EXP_NUM]\n",
    "    #     axs[EXP_NUM].plot(tr['time_r'], tr['Loss'])\n",
    "\n",
    "    means = trials_gr.mean()\n",
    "    q_lower = trials_gr.quantile(q=q1,interpolation='lower')\n",
    "    q_mid = trials_gr.quantile(q=q3,interpolation='linear')\n",
    "    q_higher = trials_gr.quantile(q=q2,interpolation='higher')\n",
    "    \n",
    "    f = plt.figure()\n",
    "    \n",
    "    ax1 = f.add_subplot()\n",
    "\n",
    "    ax1.fill_between(x=means.index, y1=q_lower['Loss'], y2=q_higher['Loss'],alpha=0.4)\n",
    "    ax1.plot(q_lower['Loss'], label=f'Q{int(q1*100)}',c='black',lw=0.6)\n",
    "    ax1.plot(q_higher['Loss'], label=f'Q{int(q2*100)}',c='black',lw=0.6)\n",
    "    ax1.plot(q_mid['Loss'], label='Median',c='darkorange')\n",
    "    ax1.plot(means['Loss'], label='Mean')\n",
    "    ax1.set_ylim(bottom=f_ylim[0], top=f_ylim[1])\n",
    "    \n",
    "    xt = ax1.get_xticks()\n",
    "    xt_ind = xt[1:-1] - 1\n",
    "    xt_ind[0] = 0\n",
    "    # ax1.set_xticks(means['SampleSize'].cumsum()[xt_ind])\n",
    "    # ax1.set_xticklabels(labels=np.round(means['SampleSize'].cumsum()[xt_ind], 0), rotation=45)\n",
    "\n",
    "    ax1.set_xlabel('time, s')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    \n",
    "    f_ = plt.figure()\n",
    "    ax2 = f_.add_subplot()\n",
    "\n",
    "    ax2.fill_between(x=means.index, y1=q_lower['C1'], y2=q_higher['C1'],alpha=0.4)\n",
    "    ax2.plot(q_lower['C1'], ls = '-', label=f'Q{int(q1*100)}',c='black', lw=0.6)\n",
    "    ax2.plot(q_higher['C1'], ls = '-', label=f'Q{int(q2*100)}',c='black', lw=0.6)\n",
    "    ax2.plot(q_mid['C1'], label='Median',c='darkorange')\n",
    "    ax2.plot(means['C1'], label='Mean')\n",
    "\n",
    "    ax2.set_xlabel('time, s')\n",
    "    # ax2.set_ylim(bottom=-0.02, top=0.02)\n",
    "    ax2.hlines(y=[-lb, lb], xmin=0, xmax=max(means.index), ls='--',colors='blue', alpha=0.5, label='Constraint bound')\n",
    "    ax2.hlines(y=0, xmin=0, xmax=max(means.index), ls='--', colors='black', alpha=0.5)\n",
    "    ax2.set_ylabel('$L_w-L_b$')\n",
    "    ax2.legend()\n",
    "    ax2.set_ylim(bottom=c_ylim[0], top=c_ylim[1])\n",
    "    \n",
    "    return f, f_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_parameter_string(s):\n",
    "    s = s.lstrip('_')\n",
    "    variables = ['lambda', 'gamma', 'zeta', 'beta', 'rho', 'tau', 'ss', 'a']\n",
    "    numeric_vars = [v for v in variables if v != 'ss']\n",
    "    ss_var = 'ss'\n",
    "    \n",
    "    numeric_part = '|'.join(numeric_vars)\n",
    "    lookahead = f'(?={numeric_part}|{ss_var}|$)'\n",
    "    \n",
    "    pattern = re.compile(\n",
    "        rf'({ss_var})(.*?){lookahead}'  # \"ss\" with arbitrary value\n",
    "        rf'|({\"|\".join(numeric_vars)})(\\d+\\.?\\d*){lookahead}'  # numeric vars\n",
    "    )\n",
    "    \n",
    "    result = {}\n",
    "    for match in pattern.finditer(s):\n",
    "        if match.group(1):  # \"ss\" case\n",
    "            result[match.group(1)] = match.group(2)\n",
    "        else:  # numeric case\n",
    "            result[match.group(3)] = float(match.group(4))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read results:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = 'income'\n",
    "STATE = 'ok'\n",
    "\n",
    "DATASET = TASK +'_'+ STATE\n",
    "lb = 0.005\n",
    "geomp = 0.4\n",
    "sampling = 1\n",
    "alg = 'sslalm'\n",
    "alg_param_str = '_mu2.0rho1.0tau0.01eta0.05beta0.5'\n",
    "# alg = 'sg'\n",
    "# alg_param_str = '_a0.4rho0.8beta10.0lambda0.5gamma0.05zeta0.05tau1.0ssdimin'\n",
    "alg += alg_param_str\n",
    "constraint = 'loss'\n",
    "\n",
    "if alg.startswith('sg') and not alg.startswith('sgd'):\n",
    "    filename = f'./utils/exp_results/{alg}_' + f'{DATASET}_{lb}_{geomp}.csv'\n",
    "else:\n",
    "    filename = f'./utils/exp_results/{alg}_' + f'{DATASET}_{lb}.csv'\n",
    "    \n",
    "stats = pd.read_csv(filename)\n",
    "if alg_param_str.startswith('_mu0'):\n",
    "    alg = 'sslalm_aug'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_train = stats[stats['is_train'] == 'train'].drop(['is_train'], axis=1).dropna()\n",
    "stats_test = stats[stats['is_train'] == 'test'].drop(['is_train'], axis=1).dropna()\n",
    "if 'time' in stats_test.columns:\n",
    "    for trial_num in stats_test['trial'].unique():\n",
    "        trial_start_time = stats_test.loc[stats_test['trial'] == trial_num].iloc[0]['time']\n",
    "        stats_test.loc[stats_test['trial'] == trial_num, 'time'] -= trial_start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plots w.r.t. time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "alg_name = 'sslalm_aug' if alg.startswith('sslalm_mu0') else alg.split('_')[0]\n",
    "os.makedirs(os.path.dirname(f'./plots/{alg}/{DATASET}/'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1tr_time, f2tr_time = produce_plots_time(stats_train, lb, round_step=0.0005, f_ylim = (0.4, 0.77), c_ylim=(-0.12, 0.12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1tr_time.savefig(f'./plots/{alg.removesuffix(alg_param_str)}/{DATASET}/loss_train_time_{DATASET}')\n",
    "f2tr_time.savefig(f'./plots/{alg.removesuffix(alg_param_str)}/{DATASET}/c_train_time_{DATASET}')\n",
    "print(f'./plots/{alg.removesuffix(alg_param_str)}/{DATASET}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1t_time, f2t_time = produce_plots_time(stats_test, lb, round_step=0.0005, f_ylim = (0.4, 0.77), c_ylim=(-0.12, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1t_time.savefig(f'./plots/{alg.removesuffix(alg_param_str)}/{DATASET}/loss_test_time_{DATASET}')\n",
    "f2t_time.savefig(f'./plots/{alg.removesuffix(alg_param_str)}/{DATASET}/c_test_time_{DATASET}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plots w.r.t. iteration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_train[['trial', 'iteration']].groupby(by='trial').max().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1tr, f2tr = produce_plots(stats_train, lb, 'iteration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1t, f2t = produce_plots(stats_test, lb, 'iteration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trajectories:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_separate_trajectories(stats_train, lb, 'iteration', alpha=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hcomp-cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
